{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5196 Assessment 1\n",
    "#### Student Name: DEEPALI VINAY  and MINGLEI WANG\n",
    "#### Student ID: 30281229 and 26263092\n",
    "\n",
    "Start Date: 11/08/2019\n",
    "\n",
    "Finish Date: 25/08/2019\n",
    "\n",
    "Version: 2.0\n",
    "\n",
    "Environment: Python 3.7.1 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas (for dataframe and exporting csv) \n",
    "* re (for regular expression)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Introduction\n",
    "The below program extracts the data from an input file in text format, and cleans, transforms and exports the data into CSV and JSON formats.\n",
    "\n",
    "The input file used here is `group020.txt`, it comprises of 150 patent details. \n",
    "The required tasks are the following:\n",
    "\n",
    "1. Reading `group020.txt` file which contains the details of the patents.\n",
    "2. Extract the relevent information for each of the patents.\n",
    "3. Storing/exporting data in a structured csv (`Group020.csv`) and json (`Group020.json`) formats. \n",
    "\n",
    "More details for the task will be given in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import libraries \n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Parse Group020 File\n",
    "#### 3.1 Reading the input file\n",
    "\n",
    "We are using the python file handling feature to open the text file in default read mode and storing the content of the input file in a variable `line` as a string. Also we are opening a `Group020.json` file in write mode to later generate a json output from the given input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file=open('Group020.txt')\n",
    "line=input_file.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the below cell we are spliting the input text file with `<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n` as a separator and ignoring the first blank element from the resulting list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list=line.split(sep='<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in the next cell we are creating an empty dataframe with the specified column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(columns=['grant_id','patent_title','kind','number_of_claims','inventors','citations_applicant_count',\\\n",
    "                         'citations_examiner_count','claims_text','abstract']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are opening a file in write mode which will be used to store output in json format. As observed in the sample output file, we are writing the first character `{` into the json file `Group020.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file=open('Group020.json','w')\n",
    "json_file.write('{');                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Extracting data\n",
    "\n",
    "* In this part of the program we will be extracting all the patents and the relevent data for each of them from the input file. Each of the columns in the dataframe created will be extracted using appropriate regular expressions.\n",
    "\n",
    "* There are nine columns specified which are grant_id, patent_kind, patent_title, number_of_claims, citations_examiner_count, citations_applicant_count, inventors, claims_text and abstract.\n",
    "\n",
    "* There is a for loop iterating over each patent and an empty dictionary `dic` is initialised for each iteration, which will hold the column name as the key, and the corresponding value of column as value, before the dictionary is reset in the following iteration.\n",
    "    \n",
    "* As soon as a data is fetched and stored into the dictionary, the same data is written into the output json file following the json file format using the python file handling capabilities.\n",
    "\n",
    "* In the end of the for loop we will append the dictionary to the dataframe, hence after each iteration in the for loop, we will obtain one new row in the dataframe i.e., each iteration will provide details of a new patent id. \n",
    "\n",
    "NOTE: Further description of the below code is provided as inline/block comments.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterating for each elemnent in the data_list\n",
    "for each in data_list:\n",
    "    dic={}        # creating an empty dictionary\n",
    "    \n",
    "    each=each.replace(\"&#x2018;\",\"'\").replace(\"&#x2019;\",\"'\").replace(\"&#x2212;\",\"-\") # replacing the unicode with a meaningful symbol\n",
    "    \n",
    "    \n",
    "    ''' retrieving grant_id :\n",
    "        Matching and fetching grant_id only if it consists of zero or more word characters i.e. [a-zA-Z0-9_] \n",
    "        between the specified pattern of substrings.\n",
    "    '''\n",
    "    \n",
    "    grant_id=re.search(r'<us-patent-grant.*file=\"(\\w*)-',each)       # searching for the specified pattern\n",
    "    dic[\"grant_id\"]=grant_id.group(1)                                # updating the dictionary with the value for grant_id\n",
    "    json_file.write('\"'+dic[\"grant_id\"]+'\":{')                       # writing the grant_id into json_file \n",
    "     \n",
    "    \n",
    "    ''' retrieving patent_title :\n",
    "        Matching and fetching patent_title details consisting of any type of character, \n",
    "        appearing zero or more number of times between the specified pattern of substrings.\n",
    "    '''\n",
    "    \n",
    "    patent_title=re.search(r'<invention-title id.*>(.*)</invention-title>',each)   # searching for the specified pattern                                                                              \n",
    "    dic['patent_title']=patent_title.group(1)                       # updating the dictionary with the value for patent_title\n",
    "    json_file.write('\"patent_title\":\"'+dic['patent_title']+'\",')                   # writing the patent_title into json_file \n",
    "    \n",
    "    \n",
    "    ''' kind :\n",
    "        Matching and fetching kind details of patent consisting of any type of character (except \\n)\n",
    "        appearing zero or more number of times between the specified pattern of substrings. \n",
    "        Since the metacharacter dot in regex does not include new line character we are explicitly \n",
    "        replacing \\n with blank.\n",
    "    '''\n",
    "    kind=re.search(r'<publication-reference>(.*?)<kind>(.*?)</kind>',each.replace('\\n','')) # search for the specified pattern\n",
    "    \n",
    "    # creating a lookup dictionary using the observations from the sample input and output provided\n",
    "    kind_dic={'S1':'Design Patent',\\\n",
    "              'P2':'Plant Patent Grant (no published application) issued on or after January 2, 2001',\\\n",
    "              'P3':'Plant Patent Grant (with a published application) issued on or after January 2, 2001',\\\n",
    "              'E1':'Reissue Patent',\\\n",
    "              'B1':'Utility Patent Grant (no published application) issued on or after January 2, 2001.',\\\n",
    "              'B2':'Utility Patent Grant (with a published application) issued on or after January 2, 2001.'}\n",
    "    dic['kind']=kind_dic[kind.group(2)]     # using the look up dictionary and updating 'dic' dictionary with value for kind\n",
    "    json_file.write('\"kind\":\"'+kind_dic[kind.group(2)]+'\",')                      # writing the kind into json_file\n",
    "    \n",
    "    \n",
    "    '''number_of_claims :\n",
    "       Matching and fetching number of claims for each patent, consisting of any type of character, \n",
    "       appearing zero or more number of times between the specified pattern of substrings.\n",
    "    '''\n",
    "    number_of_claims=re.search(r'<number-of-claims>(.*)</number-of-claims>',each) # searching for the specified pattern\n",
    "    dic['number_of_claims']=number_of_claims.group(1)                             # update the dictionary with the searched value\n",
    "    json_file.write('\"number_of_claims\":'+number_of_claims.group(1)+',')          # writing the number_of_claims into json_file\n",
    "    \n",
    "    \n",
    "     \n",
    "    ''' inventor :\n",
    "        Matching pattern and fetching all the inventors of a patent, consisting of any type of character (except \\n)\n",
    "        appearing zero or more number of times between the specified pattern of substrings. \n",
    "        Since the metacharacter dot in regex does not include new line character we are explicitly \n",
    "        replacing \\n with blank.\n",
    "    '''\n",
    "    temp_inventor=re.search(r'<inventors>(.*)</inventors>',each.replace('\\n','')) # search for the specified pattern\n",
    "    fname=re.findall(r'<first-name>(.*?)</first-name>',temp_inventor.group(1))    # find all occurences of the pattern \n",
    "    lname=re.findall(r'<last-name>(.*?)</last-name>',temp_inventor.group(1))      # find all occurences of the pattern \n",
    "   \n",
    "    if len(fname)==0 & len(lname)==0:          \n",
    "        dic['inventors']='[NA]'             # if no inventors were found in the search, update the dictionary with [NA]\n",
    "    else:\n",
    "        lot=list(zip(fname,lname))          # else create a list of tuples, where each tuple is a (fname,lname) pair\n",
    "        dic['inventors']='['+','.join([\" \".join(list(i)) for i in lot])+']'  # make an appropriate string and update the dictionary\n",
    "    json_file.write('\"inventors\":\"'+dic['inventors']+'\",')                   # writing the inventors into json_file\n",
    "    \n",
    "    \n",
    "    '''citations_applicant_count & citations_examiner_count :\n",
    "       Finding the count of citations by applicant and examiner of a patent. First getting both the citations \n",
    "       by matching the pattern consisting of any type of character (except \\n) appearing zero or more number \n",
    "       of times between the specified pattern of substrings and then counting the occurances of each citation type.\n",
    "       Since the metacharacter dot in regex does not include new line character we are explicitly \n",
    "       replacing \\n with blank.\n",
    "    '''\n",
    "    temp_citation=re.search(r'<us-references-cited>(.*)</us-references-cited>', each.replace('\\n',''))\n",
    "    #count citations_applicant\n",
    "    if temp_citation :\n",
    "        applicant_count=len(re.findall(r'cited by applicant',temp_citation.group(1)))\n",
    "    else:\n",
    "        applicant_count=0\n",
    "    #count citations_examiner    \n",
    "    if temp_citation:\n",
    "        examiner_count=len(re.findall(r'cited by examiner',temp_citation.group(1)))\n",
    "    else:\n",
    "        examiner_count=0\n",
    "    dic['citations_applicant_count']=applicant_count\n",
    "    json_file.write('\"citations_applicant_count\":'+str(applicant_count)+',')\n",
    "    #store two counts to dic\n",
    "    dic['citations_examiner_count']=examiner_count\n",
    "    json_file.write('\"citations_examiner_count\":'+str(examiner_count)+',')\n",
    "    \n",
    "    \n",
    "    '''claim_text '''\n",
    "    \n",
    "    raw_text=re.search(r'<claims id=\"claims\">(.*)</claims>', each.replace('\\n','')) #search for the specified pattern\n",
    "    \n",
    "    #if a pattern was found in the search\n",
    "    if raw_text:\n",
    "        claim_list=raw_text.group(1).strip().split('</claim>')    # split at the occurences of '</claim>' into a list\n",
    "        claims=[re.sub(r'<.*?>','',j) for j in claim_list][:-1]   # remove tags for each element of the list\n",
    "        claims_text=\"[\"+','.join(claims)+\"]\"                      # change list to a comma separated string\n",
    "        dic['claims_text']=claims_text                            # updating the dictionary for claims_text\n",
    "    \n",
    "    #if no patterns found in the search\n",
    "    else:\n",
    "        dic['claims_text']='[NA]'                                 # updating the dictionary with '[NA]' for claims_text\n",
    "        \n",
    "    json_file.write('\"claims_text\":\"'+dic['claims_text']+'\",')    # writing the value to json_file\n",
    "   \n",
    "    \n",
    "    '''abstract '''\n",
    "    \n",
    "    temp_abstract=re.search(r'<abstract id=\"abstract\">(.*)</abstract>',each.replace('\\n','')) # search for the specified pattern\n",
    "    \n",
    "    #if a pattern was found in the search\n",
    "    if temp_abstract:\n",
    "        abstract_data=temp_abstract.group(1)\n",
    "        abstract=re.sub(r'<.*?>','',abstract_data)  # removing the tags, by substituting the pattern with nothing\n",
    "        dic['abstract']=abstract                    # updating the dictionary with the value for abstract\n",
    "    \n",
    "    #if no patterns found in the search\n",
    "    else:\n",
    "        dic['abstract']='NA'                        # updating the dictionary with 'NA' for abstract\n",
    "    json_file.write('\"abstract\":\"'+dic['abstract']+'\"},') \n",
    "        \n",
    "    df=df.append(dic, ignore_index=True)            # append dictionary to dateframe and ignore index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Creating csv and json output files\n",
    "We convert the dataframe to csv format and create a file named `Group020.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Group020.csv', index=False)        # creating csv file and ignoring dataframe index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we complete the json file with `}` and close the earlier opened files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the current cursor position and replacing the last character (comma) with '}'\n",
    "json_file.seek(json_file.tell()-1)   \n",
    "json_file.write('}')\n",
    "\n",
    "# closing the files\n",
    "json_file.close() \n",
    "input_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Summary\n",
    "\n",
    "This assessment tested the overall python coding knowledge, working with different data types(integers, dictionaries, lists, strings etc), pandas, regex and \n",
    "finally documenting skills. We understood, how meaningful data can be fetched from a file with raw data by studying/analysing the patterns and extracting the right information.\n",
    "\n",
    "**regex** : regular expression was extensively used to search for a particular pattern/substring\n",
    "\n",
    "**pandas** : pandas was used to organise data in a dataframe and then export it to a csv file succesfully\n",
    "\n",
    "**file operations**: Python file operations were used to write the data to a json file as observed in the sample output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
